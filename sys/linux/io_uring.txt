# Copyright 2019 syzkaller project authors. All rights reserved.
# Use of this source code is governed by Apache 2 LICENSE that can be found in the LICENSE file.

# See http://kernel.dk/io_uring.pdf

# NEED: we somehow need to write the mmap-ed range after the mmap. vring needs something similar.

include <uapi/linux/io_uring.h>
# For EPOLL_CTL_ADD, EPOLL_CTL_MOD, EPOLL_CTL_DEL
include <uapi/linux/eventpoll.h>

resource fd_io_uring[fd]
resource sq_ring_ptr[int64]
resource cq_ring_ptr[int64]
resource sqes_ptr[int64]
resource ioring_register_personality_id[int32]

# fs/io_uring.c
define IORING_MAX_ENTRIES	32768
define IORING_MAX_CQ_ENTRIES	(2 * IORING_MAX_ENTRIES)

# TODO: if the requested entries exceed the max, IORING_SETUP_CLAMP can be used to successfully setup by clamping the entries to max
io_uring_setup(entries int32[1:IORING_MAX_ENTRIES], params ptr[inout, io_uring_params]) fd_io_uring
io_uring_enter(fd fd_io_uring, to_submit int32[0:IORING_MAX_ENTRIES], min_complete int32[0:IORING_MAX_CQ_ENTRIES], flags flags[io_uring_enter_flags], sigmask ptr[in, sigset_t], size len[sigmask])
io_uring_register$IORING_REGISTER_BUFFERS(fd fd_io_uring, opcode const[IORING_REGISTER_BUFFERS], arg ptr[in, array[iovec_out]], nr_args len[arg])
io_uring_register$IORING_UNREGISTER_BUFFERS(fd fd_io_uring, opcode const[IORING_UNREGISTER_BUFFERS], arg const[0], nr_args const[0])
io_uring_register$IORING_REGISTER_FILES(fd fd_io_uring, opcode const[IORING_REGISTER_FILES], arg ptr[in, array[fd]], nr_args len[arg])
io_uring_register$IORING_UNREGISTER_FILES(fd fd_io_uring, opcode const[IORING_UNREGISTER_FILES], arg const[0], nr_args const[0])
io_uring_register$IORING_REGISTER_EVENTFD(fd fd_io_uring, opcode const[IORING_REGISTER_EVENTFD], arg ptr[in, fd_event], nr_args const[1])
io_uring_register$IORING_UNREGISTER_EVENTFD(fd fd_io_uring, opcode const[IORING_UNREGISTER_EVENTFD], arg const[0], nr_args const[0])
io_uring_register$IORING_REGISTER_FILES_UPDATE(fd fd_io_uring, opcode const[IORING_REGISTER_FILES_UPDATE], arg ptr[in, io_uring_files_update], nr_args len[arg:fds])
io_uring_register$IORING_REGISTER_EVENTFD_ASYNC(fd fd_io_uring, opcode const[IORING_REGISTER_EVENTFD_ASYNC], arg ptr[in, fd_event], nr_args const[1])
io_uring_register$IORING_REGISTER_PROBE(fd fd_io_uring, opcode const[IORING_REGISTER_PROBE], arg ptr[inout, io_uring_probe], nr_args len[arg:ops])
io_uring_register$IORING_REGISTER_PERSONALITY(fd fd_io_uring, opcode const[IORING_REGISTER_PERSONALITY], arg const[0], nr_args const[0]) ioring_register_personality_id
io_uring_register$IORING_UNREGISTER_PERSONALITY(fd fd_io_uring, opcode const[IORING_UNREGISTER_PERSONALITY], arg const[0], nr_args ioring_register_personality_id)

mmap$IORING_OFF_SQ_RING(addr vma, len len[addr], prot flags[mmap_prot], flags flags[mmap_flags], fd fd_io_uring, offset const[IORING_OFF_SQ_RING]) sq_ring_ptr
mmap$IORING_OFF_CQ_RING(addr vma, len len[addr], prot flags[mmap_prot], flags flags[mmap_flags], fd fd_io_uring, offset const[IORING_OFF_CQ_RING]) cq_ring_ptr
mmap$IORING_OFF_SQES(addr vma, len len[addr], prot flags[mmap_prot], flags flags[mmap_flags], fd fd_io_uring, offset const[IORING_OFF_SQES]) sqes_ptr

# If no flags are specificed(0), the io_uring instance is setup for interrupt driven IO.
io_uring_setup_flags = 0, IORING_SETUP_IOPOLL, IORING_SETUP_SQPOLL, IORING_SETUP_SQ_AFF, IORING_SETUP_CQSIZE, IORING_SETUP_CLAMP
io_uring_enter_flags = IORING_ENTER_GETEVENTS, IORING_ENTER_SQ_WAKEUP
_ = __NR_mmap2

# TODO: Consume anything registered within io_uring_sqes as well.

# The ops array in io_uring_probe might contain at most the number available
# IORING_OP many entries, which corresponds to IORING_OP_LAST. Thus, while
# probing, let's probe for all and ensure that the kernel can fit all if all of
# them are supported.
define IO_URING_PROBE_OPS_SIZE	IORING_OP_LAST

# NEED: part of fields are input here and part are output. We can't express this yet (#245).
# Only the ops and ops_len is passed in, rest is to be set by kernel
io_uring_probe {
	last_op	int8
	ops_len	len[ops, int8]
	resv	const[0, int16]
	resv2	array[const[0, int32], 3]
	ops	array[io_uring_probe_op, IO_URING_PROBE_OPS_SIZE]
}

# Values are to be set by kernel
io_uring_probe_op {
	op	int8
	resv	const[0, int8]
	flags	int16
	resv2	const[0, int32]
}

io_uring_files_update {
	offset	int32
	resv	int32
	fds	ptr[in, array[fd]]
}

syz_io_uring_complete(cq_ring_ptr cq_ring_ptr, cqe ptr[out, io_uring_cqe])

# Read from the cq ring using syz_io_uring_complete() but not really used anywhere else
# TODO: Check if we need to utilize io_uring_cqe anywhere else
io_uring_cqe {
	user_data	int64
	res		int32
	flags		int32
}

# NEED: part of fields are input here and part are output. We can't express this yet (#245).
io_uring_params {
# sq_entries, cq_entries, features, wq_fd, sq_off, and cq_off are set by the kernel
	sq_entries	const[0, int32]
	cq_entries	const[0, int32]
	flags		flags[io_uring_setup_flags, int32]
	sq_thread_cpu	int32[0:3]
	sq_thread_idle	int32[0:1000]
	features	const[0, int32]
# TODO: If IORING_SETUP_ATTACH_WQ is set for io_uring_setup(), wq_fd is expected
# to be a valid io_uring_fd. Utilize this flag.
	wq_fd		const[0, int32]
	resv		array[const[0, int32], 3]
	sq_off		io_sqring_offsets
	cq_off		io_cqring_offsets
}

# NOTE: We don't really use the offsets (io_sqring_offsets, io_cqring_offsets). 
# Instead, they are hard-coded or computed when needed (i.e., inside syz_io_uring_submit()
# and syz_io_uring_complete()).
io_sqring_offsets {
	head		const[0, int32]
	tail		const[0, int32]
	ring_mask	const[0, int32]
	ring_entries	const[0, int32]
	flags		const[0, int32]
	dropped		const[0, int32]
	array		const[0, int32]
	resv1		const[0, int32]
	resv2		const[0, int64]
}

io_cqring_offsets {
	head		const[0, int32]
	tail		const[0, int32]
	ring_mask	const[0, int32]
	ring_entries	const[0, int32]
	overflow	const[0, int32]
	cqes		const[0, int32]
	flags		const[0, int32]
	resv1		const[0, int32]
	resv2		const[0, int64]
}

# NEED: To avoid so much boilerplate, use call templates (when implemented).
syz_io_uring_submit$IORING_OP_NOP(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_nop], sqes_index int32)
syz_io_uring_submit$IORING_OP_READV(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_readv], sqes_index int32)
syz_io_uring_submit$IORING_OP_WRITEV(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_writev], sqes_index int32)
syz_io_uring_submit$IORING_OP_FSYNC(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_fsync], sqes_index int32)
syz_io_uring_submit$IORING_OP_READ_FIXED(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_read_fixed], sqes_index int32)
syz_io_uring_submit$IORING_OP_WRITE_FIXED(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_write_fixed], sqes_index int32)
syz_io_uring_submit$IORING_OP_POLL_ADD(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_poll_add], sqes_index int32)
syz_io_uring_submit$IORING_OP_POLL_REMOVE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_poll_remove], sqes_index int32)
syz_io_uring_submit$IORING_OP_SYNC_FILE_RANGE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_sync_file_range], sqes_index int32)
syz_io_uring_submit$IORING_OP_SENDMSG(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_sendmsg], sqes_index int32)
syz_io_uring_submit$IORING_OP_RECVMSG(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_recvmsg], sqes_index int32)
syz_io_uring_submit$IORING_OP_TIMEOUT(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_timeout], sqes_index int32)
syz_io_uring_submit$IORING_OP_TIMEOUT_REMOVE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_timeout_remove], sqes_index int32)
syz_io_uring_submit$IORING_OP_ACCEPT(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_accept], sqes_index int32)
syz_io_uring_submit$IORING_OP_ASYNC_CANCEL(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_async_cancel], sqes_index int32)
syz_io_uring_submit$IORING_OP_LINK_TIMEOUT(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_link_timeout], sqes_index int32)
syz_io_uring_submit$IORING_OP_CONNECT(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_connect], sqes_index int32)
syz_io_uring_submit$IORING_OP_FALLOCATE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_fallocate], sqes_index int32)
syz_io_uring_submit$IORING_OP_OPENAT(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_openat], sqes_index int32)
syz_io_uring_submit$IORING_OP_CLOSE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_close], sqes_index int32)
syz_io_uring_submit$IORING_OP_FILES_UPDATE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_files_update], sqes_index int32)
syz_io_uring_submit$IORING_OP_STATX(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_statx], sqes_index int32)
syz_io_uring_submit$IORING_OP_READ(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_read], sqes_index int32)
syz_io_uring_submit$IORING_OP_WRITE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_write], sqes_index int32)
syz_io_uring_submit$IORING_OP_FADVISE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_fadvise], sqes_index int32)
syz_io_uring_submit$IORING_OP_MADVISE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_madvise], sqes_index int32)
syz_io_uring_submit$IORING_OP_SEND(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_send], sqes_index int32)
syz_io_uring_submit$IORING_OP_RECV(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_recv], sqes_index int32)
syz_io_uring_submit$IORING_OP_OPENAT2(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_openat2], sqes_index int32)
syz_io_uring_submit$IORING_OP_EPOLL_CTL(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_epoll_ctl], sqes_index int32)
syz_io_uring_submit$IORING_OP_SPLICE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_splice], sqes_index int32)
syz_io_uring_submit$IORING_OP_PROVIDE_BUFFERS(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_provide_buffers], sqes_index int32)
syz_io_uring_submit$IORING_OP_REMOVE_BUFFERS(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_remove_buffers], sqes_index int32)
syz_io_uring_submit$IORING_OP_TEE(sq_ring_ptr sq_ring_ptr, sqes_ptr sqes_ptr, sqe ptr[in, io_uring_sqe_tee], sqes_index int32)

# TODO: IORING_OP_IOCTL

# io_uring_sqe

# TODO: add IOSQE_FIXED_FILE_BIT and IOSQE_BUFFER_SELECT_BIT to iosqe_flags.
# When IOSQE_FIXED_FILE_BIT is specified, fd is an index into the files array
# registered with the io_uring instance (using io_uring_register()).
# When IOSQE_BUFFER_SELECT is specified, the buffer is selected from 
# sqe->buf_group (as registered using io_uring_register()) only supported for
# READV, READ, RECV, RECVMSG.
# The above flags are more tricky and the content of sqe for the operations should
# change if they are specified.
iosqe_flags = IOSQE_IO_DRAIN_BIT, IOSQE_IO_LINK_BIT, IOSQE_IO_HARDLINK_BIT, IOSQE_ASYNC_BIT

# IORING_OP_NOP
io_uring_sqe_nop {
	opcode		const[IORING_OP_NOP, int8]
	fill_unused	array[const[0, int8], 63]
}

# IORING_OP_READV, IORING_OP_WRITEV
type io_uring_sqe_rw_v[OP_V_RW, IOVEC_INOUT] {
	opcode		const[OP_V_RW, int8]
	flags		flags[iosqe_flags, int8]
	ioprio		flags[ioprio_priorities, int16]
	fd		fd
	off		fileoff[int64]
	addr		ptr[in, array[IOVEC_INOUT]]
	len		len[addr, int32]
	rw_flags	flags[rwf_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

type io_uring_sqe_readv io_uring_sqe_rw_v[IORING_OP_READV, iovec_out]
type io_uring_sqe_writev io_uring_sqe_rw_v[IORING_OP_WRITEV, iovec_in]

# IORING_OP_FSYNC
io_uring_sqe_fsync {
	opcode		const[IORING_OP_FSYNC, int8]
	flags		flags[iosqe_flags, int8]
	ioprio		const[0, int16]
	fd		fd
	off_unused	const[0, int64]
	addr_unused	const[0, int64]
	len_unused	const[0, int32]
	fsync_flags	flags[io_uring_fsync_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# 0 for normal file integrity sync, IORING_FSYNC_DATASYNC to provide data sync only semantics
io_uring_fsync_flags = 0, IORING_FSYNC_DATASYNC

# IORING_OP_READ_FIXED, IORING_OP_WRITE_FIXED
type io_uring_sqe_rw_fixed[OP_FIXED_RW] {
	opcode		const[OP_FIXED_RW, int8]
	flags		flags[iosqe_flags, int8]
	ioprio		flags[ioprio_priorities, int16]
	fd		fd
	off		fileoff[int64]
# addr and len for the buffer located at buf_index
	addr		int64
	len		int32
	rw_flags	flags[rwf_flags, int32]
	user_data	sqe_user_data
	buf_index	io_uring_bid[int16]
	pad_unused	array[const[0, int8], 22]
}

type io_uring_sqe_read_fixed io_uring_sqe_rw_fixed[IORING_OP_READ_FIXED]
type io_uring_sqe_write_fixed io_uring_sqe_rw_fixed[IORING_OP_WRITE_FIXED]

# IORING_OP_POLL_ADD
io_uring_sqe_poll_add {
	opcode			const[IORING_OP_POLL_ADD, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd
	off_unused		const[0, int64]
	addr_unused		const[0, int64]
	len_unused		const[0, int32]
	poll_events		flags[pollfd_events, int16]
# 2 bytes of padding to fill what is left from the union of flags
	fill_flags_union	const[0, int16]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_POLL_REMOVE
io_uring_sqe_poll_remove {
	opcode			const[IORING_OP_POLL_REMOVE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd_unused		const[0, int32]
	off_unused		const[0, int64]
	addr			sqe_user_data
	len_unused		const[0, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_SYNC_FILE_RANGE
io_uring_sqe_sync_file_range {
	opcode			const[IORING_OP_SYNC_FILE_RANGE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd
	off			fileoff[int64]
	addr_unused		const[0, int64]
	len			int32
	sync_range_flags	flags[sync_file_flags, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_SENDMSG
io_uring_sqe_sendmsg {
	opcode		const[IORING_OP_SENDMSG, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		sock
	off_unused	const[0, int64]
	addr		ptr[in, send_msghdr]
# TODO: do we need len? It is read in fs/io_uring.c but why? req->sr_msg->buf's len.
	len_unused	const[0, int32]
	msg_flags	flags[send_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_RECVMSG
io_uring_sqe_recvmsg {
	opcode		const[IORING_OP_RECVMSG, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		sock
	off_unused	const[0, int64]
	addr		ptr[inout, recv_msghdr]
# TODO: do we need len? It is read in fs/io_uring.c but why? req->sr_msg->buf's len.
	len_unused	const[0, int32]
	msg_flags	flags[recv_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_TIMEOUT

io_uring_sqe_timeout {
	opcode		const[IORING_OP_TIMEOUT, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd_unused	const[0, int32]
# Completion event count. The timeout condition is met when either
# the specific timeout expries, or the specified number of events have
# completed.  If not set, defaults to 1. Use a limited range to allow
# utilization of this value to meet timeout condition besides the timeout
# expiration.
	off		int64[0:10]
	addr		ptr[in, timespec]
# Signify one timespec64 structure
	len		const[1, int32]
	timeout_flags	flags[io_uring_timeout_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# 0 for relative, IORING_TIMEOUT_ABS for absolute timeout value
io_uring_timeout_flags = 0, IORING_TIMEOUT_ABS

# IORING_OP_TIMEOUT_REMOVE
io_uring_sqe_timeout_remove {
	opcode		const[IORING_OP_TIMEOUT_REMOVE, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd_unused	const[0, int32]
	off_unused	const[0, int64]
	addr		sqe_user_data
	len_unused	const[0, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_ACCEPT
io_uring_sqe_accept {
	opcode		const[IORING_OP_ACCEPT, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		sock
	addr2		ptr[inout, len[addr, int32]]
	addr		ptr[out, sockaddr_storage, opt]
	len_unused	const[0, int32]
	accept_flags	flags[accept_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_ASYNC_CANCEL

# An already issued request can be attempted to be cancelled using ASYNC_CANCEL
# operation. This operation identifies the operations using what's passed as
# with user_data in their sqe. To ease collisions of ASYNC_CANCEL operation with
# already submitted ones, use a limited range of values for user_data field.
type sqe_user_data int64[0:10]

io_uring_sqe_async_cancel {
	opcode			const[IORING_OP_ASYNC_CANCEL, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd_unused		const[0, int32]
	off_unused		const[0, int64]
	addr			sqe_user_data
	len_unused		const[0, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_LINK_TIMEOUT
io_uring_sqe_link_timeout {
	opcode		const[IORING_OP_LINK_TIMEOUT, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd_unused	const[0, int32]
	off_unused	const[0, int64]
	addr		ptr[in, timespec]
# Signify one timespec64 structure
	len		const[1, int32]
	timeout_flags	flags[io_uring_timeout_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_CONNECT
io_uring_sqe_connect {
	opcode			const[IORING_OP_CONNECT, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			sock
	off			len[addr, int32]
	addr			ptr[in, sockaddr_storage]
	len_unused		const[0, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_FALLOCATE
io_uring_sqe_fallocate {
	opcode			const[IORING_OP_FALLOCATE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd
	off			fileoff[int64]
	addr_unused		const[0, int64]
	len			int32
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_OPENAT
# TODO: how to use the returned fd? (maybe this is where we are going to utilize cqe?)
io_uring_sqe_openat {
	opcode		const[IORING_OP_OPENAT, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		fd_dir[opt]
	off_unused	const[0, int64]
	addr		ptr[in, filename]
	len		flags[open_mode, int32]
	open_flags	flags[open_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_CLOSE
io_uring_sqe_close {
	opcode			const[IORING_OP_CLOSE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd
	off_unused		const[0, int64]
	addr			const[0, int64]
	len_unused		const[0, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_FILES_UPDATE
io_uring_sqe_files_update {
	opcode			const[IORING_OP_FILES_UPDATE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd_unused		const[0, int32]
	off			fileoff[int64]
	addr			ptr[in, array[fd]]
	len			len[addr, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_STATX
io_uring_sqe_statx {
	opcode		const[IORING_OP_STATX, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		fd_dir[opt]
	off		ptr[out, statx]
	addr		ptr[in, filename]
	len		flags[statx_mask, int32]
	statx_flags	flags[statx_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_READ
io_uring_sqe_read {
	opcode		const[IORING_OP_READ, int8]
	flags		flags[iosqe_flags, int8]
	ioprio		flags[ioprio_priorities, int16]
	fd		fd
	off		fileoff[int64]
	addr		buffer[out]
	len		bytesize[addr, int32]
	rw_flags	flags[rwf_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_WRITE
io_uring_sqe_write {
	opcode		const[IORING_OP_WRITE, int8]
	flags		flags[iosqe_flags, int8]
	ioprio		flags[ioprio_priorities, int16]
	fd		fd
	off		fileoff[int64]
	addr		buffer[in]
	len		bytesize[addr, int32]
	rw_flags	flags[rwf_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_FADVISE
io_uring_sqe_fadvise {
	opcode		const[IORING_OP_FADVISE, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		fd
	off		fileoff[int64]
	addr_unused	const[0, int64]
	len		int32
	fadvise_advice	flags[fadvise_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_MADVISE
io_uring_sqe_madvise {
	opcode		const[IORING_OP_MADVISE, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd_unused	const[0, int32]
	off_unused	const[0, int64]
	addr		vma
	len		len[addr, int32]
	fadvise_advice	flags[madvise_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_SEND
io_uring_sqe_send {
	opcode		const[IORING_OP_SEND, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		sock
	off_unused	const[0, int64]
	addr		buffer[in]
	len		len[addr, int32]
	msg_flags	flags[send_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_RECV
io_uring_sqe_recv {
	opcode		const[IORING_OP_RECV, int8]
	flags		flags[iosqe_flags, int8]
	ioprio_unused	const[0, int16]
	fd		sock
	off_unused	const[0, int64]
	addr		buffer[inout]
	len		len[addr, int32]
	msg_flags	flags[recv_flags, int32]
	user_data	sqe_user_data
	pad_unused	array[const[0, int64], 3]
}

# IORING_OP_OPENAT2
io_uring_sqe_openat2 {
	opcode			const[IORING_OP_OPENAT2, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd_dir[opt]
	off			ptr[in, open_how]
	addr			ptr[in, filename]
	len			bytesize[off, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# IORING_OP_EPOLL_CTL
type io_uring_sqe_epoll_ctl_template[EPOLL_OP, EPOLL_EVENTS] {
	opcode			const[IORING_OP_EPOLL_CTL, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd_epoll
	off			EPOLL_EVENTS
	addr			fd
	len			const[EPOLL_OP, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	pad_unused		array[const[0, int64], 3]
}

# An epoll_ctl operation could be one of add, del, mod
io_uring_sqe_epoll_ctl [
	add	io_uring_sqe_epoll_ctl_template[EPOLL_CTL_ADD, ptr[in, epoll_event]]
	del	io_uring_sqe_epoll_ctl_template[EPOLL_CTL_DEL, const[0, int64]]
	mod	io_uring_sqe_epoll_ctl_template[EPOLL_CTL_MOD, ptr[in, epoll_event]]
]

# IORING_OP_SPLICE
io_uring_sqe_splice {
	opcode			const[IORING_OP_SPLICE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
	fd			fd
	off			fileoff[int64]
# TODO: fd is int32, the field is int64. check if such alignment is right.
	splice_off_in_unused	const[0, int32]
	splice_off_in		fd
	len			int32
	splice_flags		flags[splice_flags, int32]
	user_data		sqe_user_data
	buf_unused		const[0, int16]
	personality_unused	const[0, int16]
	splice_fd_in		fd
	pad_unused		array[const[0, int64], 2]
}

# IORING_OP_PROVIDE_BUFFERS
io_uring_sqe_provide_buffers {
	opcode			const[IORING_OP_PROVIDE_BUFFERS, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
# Number of bufs, where addr is incremented by len for each
	fd			int32
	off			io_uring_bid[int64]
	addr			buffer[in]
# Length of each buffer
	len			int32
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	buf_group		io_uring_bgid[int16]
	pad_unused		array[const[0, int8], 22]
}

# The buffer id (bid) and the buffer group id (bgid) are registered using
# IORING_OP_PROVIDE_BUFFERS. Use the ids in a limited range to ease collisions
# with other operations.
type io_uring_bid[T] T[0:10]
type io_uring_bgid[T] T[0:10]

# IORING_OP_REMOVE_BUFFERS
io_uring_sqe_remove_buffers {
	opcode			const[IORING_OP_PROVIDE_BUFFERS, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
# Number of bufs
	fd			int32
	off_unused		const[0, int64]
	addr_unusted		const[0, int64]
	len_unused		const[0, int32]
	misc_flags_unused	const[0, int32]
	user_data		sqe_user_data
	buf_group		io_uring_bgid[int16]
	pad_unused		array[const[0, int8], 22]
}

# IORING_OP_TEE
io_uring_sqe_tee {
	opcode			const[IORING_OP_TEE, int8]
	flags			flags[iosqe_flags, int8]
	ioprio_unused		const[0, int16]
# TODO: Should be pipefd
	fd			fd
	off_unused		const[0, int64]
	addr_unused		const[0, int64]
	len			int32
	splice_flags		flags[splice_flags, int32]
	user_data		sqe_user_data
	buf_unused		const[0, int16]
	personality_unused	const[0, int16]
# TODO: Should be pipefd
	splice_fd_in		fd
	pad_unused		array[const[0, int64], 2]
}
